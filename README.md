# bert

## 说明
参考 [bert-as-service](https://github.com/hanxiao/bert-as-service),只保留生成embedding的代码。

- 想要了解具体的bert实现，请参考 [google-bert](https://github.com/google-research/bert)

- 已经预训练好的模型，请访问 [模型链接](https://github.com/google-research/bert#pre-trained-models).

# ELMO-tf
> ELMO : Deep contextualized word representations 
> https://arxiv.org/abs/1802.05365
## 说明

参考 [ELMO-tf](https://github.com/codertimo/ELMO-tf),修改部分代码，适应于中文语料。
这位韩国小哥哥写的代码很清晰，相对于原始的实现，可读性好很多。原始的实现需要自行整理，搭建中文处理机制。

- 最原始的 ELMO 实现原理，请参考 [Deep contextualized word representations](https://arxiv.org/abs/1802.05365)

- 其他基于 ELMO 的chinese 版本实现，请访问 [ELMO chinese](https://github.com/searobbersduck/ELMo_Chin).

# bert_classification

基于 bert 的分类模型，下游任务（二分类、多分类、多标签分类都可以修改）







